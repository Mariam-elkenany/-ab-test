{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30014b56",
   "metadata": {},
   "source": [
    "# Analyze A/B Test Results \n",
    "\n",
    "This project will assure you have mastered the subjects covered in the statistics lessons. We have organized the current notebook into the following sections: \n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Final Check](#finalcheck)\n",
    "- [Submission](#submission)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists. For this project, you will be working to understand the results of an A/B test run by an e-commerce website.  Your goal is to work through this notebook to help the company understand if they should:\n",
    "\n",
    "<a id='probability'></a>\n",
    "## Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6acd3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)\n",
    "# Start tracking running time\n",
    "start = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb3177",
   "metadata": {},
   "source": [
    "### ToDo 1.1\n",
    "Now, read in the `ab_data.csv` data. Store it in `df`. Below is the description of the data, there are a total of 5 columns:\n",
    "\n",
    "<center>\n",
    "\n",
    "|Data columns|Purpose|Valid values|\n",
    "| ------------- |:-------------| -----:|\n",
    "|user_id|Unique ID|Int64 values|\n",
    "|timestamp|Time stamp when the user visited the webpage|-|\n",
    "|group|In the current A/B experiment, the users are categorized into two broad groups. <br>The `control` group users are expected to be served with `old_page`; and `treatment` group users are matched with the `new_page`. <br>However, **some inaccurate rows** are present in the initial data, such as a `control` group user is matched with a `new_page`. |`['control', 'treatment']`|\n",
    "|landing_page|It denotes whether the user visited the old or new webpage.|`['old_page', 'new_page']`|\n",
    "|converted|It denotes whether the user decided to pay for the company's product. Here, `1` means yes, the user bought the product.|`[0, 1]`|\n",
    "</center>\n",
    "Use your dataframe to answer the questions in Quiz 1 of the classroom.\n",
    "\n",
    "\n",
    "\n",
    "**a.** Read in the dataset from the `ab_data.csv` file and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6136561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df112855",
   "metadata": {},
   "source": [
    "**b.** Use the below cell to find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8770f2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of rows in the dataset:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2625973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce4e29",
   "metadata": {},
   "source": [
    "**c.**The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8722c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique users in the dataset:\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2253bd",
   "metadata": {},
   "source": [
    "**d.** The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f882fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of conversion in the dataset :\n",
    "df.query('converted == 1')['converted'].count() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d63f16",
   "metadata": {},
   "source": [
    "**e.** The number of times when the \"group\" is `treatment` but \"landing_page\" is not a `new_page`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87353d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of times when the \"group\" is treatment but \"landing_page\" is not a new_page.\n",
    "df.query('group == \"treatment\" and landing_page != \"new_page\"').count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c47d4c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of times when the \"group\" is control but \"landing_page\" is new_page.\n",
    "df.query('group != \"treatment\" and landing_page == \"new_page\"').count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b406c7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('(group == \"treatment\" and landing_page != \"new_page\") or (group != \"treatment\" and landing_page == \"new_page\")')['user_id'].count()\n",
    "# 1965+1928"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45daad",
   "metadata": {},
   "source": [
    "**f.** Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea88a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6286f1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d767aa",
   "metadata": {},
   "source": [
    " null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d7ff2",
   "metadata": {},
   "source": [
    "### ToDo 1.2  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9802a",
   "metadata": {},
   "source": [
    "2. For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this row truly received the new or old page. Use **Quiz 2** in the classroom to provide how we should handle these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f10e6a",
   "metadata": {},
   "source": [
    "a. Now use the answer to the quiz to create a new dataset that meets the specifications from the quiz. Store your new dataframe in **df2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c008d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(df.query('(group == \"treatment\" and landing_page != \"new_page\") or (group != \"treatment\" and landing_page == \"new_page\") or (group == \"control\" and landing_page != \"old_page\") or (group != \"control\" and landing_page == \"old_page\")').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e55f611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290585, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a10751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06467809",
   "metadata": {},
   "source": [
    "### ToDo 1.3 \n",
    "\n",
    "3. Use **df2** and the cells below to answer questions for **Quiz3** in the classroom.\n",
    "\n",
    "a. How many unique **user_ids** are in **df2**?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03a727b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d7bbc",
   "metadata": {},
   "source": [
    "b. There is one **user_id** repeated in **df2.** What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5808d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899    773192\n",
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.duplicated(['user_id'], keep=False)]['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c9c13",
   "metadata": {},
   "source": [
    "c. What is the row information for the repeat user_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a90eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.query('user_id == 773192')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17829da7",
   "metadata": {},
   "source": [
    "d. Remove one of the rows with a duplicate user_id, but keep your dataframe as df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e9e3f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2.drop(1899, inplace=True)\n",
    "df2.drop_duplicates(subset=['user_id','group','landing_page'],keep='first',inplace=True)\n",
    "#df2.user_id.drop_duplicates(inplace = True)\n",
    "df2.user_id.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb6f505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.query('user_id==773192')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb41f7",
   "metadata": {},
   "source": [
    "### ToDo 1.4  \n",
    "4. Use **df2** in the below cells to answer the quiz questions related to **Quiz 4** in the classroom.\n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf0b6041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7dd767",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control group`, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7ff8736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_convert = df2.query('group == \"control\"').converted.mean()\n",
    "control_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a327c",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2afc9163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_convert = df2.query('group == \"treatment\"').converted.mean()\n",
    "treatment_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58e96293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_diff = treatment_convert-control_convert\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d173438",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6716d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.query('landing_page == \"new_page\"').user_id.count() / df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd80507",
   "metadata": {},
   "source": [
    "**e.** Consider your results from parts (a) through (d) above, and explain below whether the new treatment group users lead to more conversions.\n",
    "\n",
    "In the previous question, we only look at the probability that an individual received the new page regardless of the groups. That is, while the half individuals reveive the new page, other nearly half individuals receive the old page as well. On the other hand, there is a small fraction between two control groups. Both the probabilty of the control and treatment groups is 0.12. **So I think there is no precise evidence that one page leads to more conversions.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790b964",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "## Part II - A/B Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de2837",
   "metadata": {},
   "source": [
    ">Since just calculated that the \"converted\" probability (or rate) for the old page is slightly higher than that of the new page, we will assume that the old page is better unless the new page proves to be definitely better at alpha (Type I error rate): 5%\n",
    "\n",
    "\n",
    "**Hypothesis Test:**\n",
    ">$$H_{0}:P_{new}-P_{old} \\leq 0 $$\n",
    ">$$H_{1}:P_{new}-P_{old} > 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb510133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_page    145310\n",
       "old_page    145274\n",
       "Name: landing_page, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.landing_page.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc16f28",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "a. What is the **convert rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "505a7eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = df2.converted.mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbf396",
   "metadata": {},
   "source": [
    "b. What is the **convert rate** for $p_{old}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a084e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_old = p_new\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff11bc2",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "666cac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = df2.query('landing_page == \"new_page\"').count()[0] \n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1de0c",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c455896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = df2.query('landing_page == \"old_page\"').count()[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e46d87",
   "metadata": {},
   "source": [
    "this one was tricky. But here we are looking at a null where there is no difference in conversion based on the page, which means the conversions for each page are the same.\n",
    "\n",
    "e. Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null. Store these $n_{new}$ 1's and 0's in **new_page_converted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b603248f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1190971027458537"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## simulate n_old transactions with a convert rate of p_new under the null\n",
    "\n",
    "#new_page_converted = np.random.binomial(1, p_new, n_new)\n",
    "#new_page_converted\n",
    "\n",
    "\n",
    "# Simulate a Sample for the treatment Group\n",
    "new_page_converted = np.random.choice([0,1], size=n_new, p=[(1-p_new) ,p_new])\n",
    "new_page_converted.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289f472",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null. Store these $n_{old}$ 1's and 0's in **old_page_converted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a749f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12045513994245358"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate n_old transactions with a convert rate of p_old under the null\n",
    "#old_page_converted = np.random.binomial(1, p_old, n_old)\n",
    "#old_page_converted\n",
    "\n",
    "# Simulate a Sample for the control Group\n",
    "old_page_converted=np.random.choice([0,1], size=n_old, p=[(1-p_old), p_old])\n",
    "old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b89f7",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08a6374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0013580371965998816"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# differences computed in from p_new and p_old\n",
    "p_new = new_page_converted.mean()\n",
    "p_old = old_page_converted.mean()\n",
    "actual_diff = p_new - p_old\n",
    "actual_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20243f4f",
   "metadata": {},
   "source": [
    "h. Simulate 10,000 $p_{new}$ - $p_{old}$ values using this same process similarly to the one you calculated in parts a. through g. above. Store all 10,000 values in p_diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d517f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffss=[]\n",
    "new_converted_simul = np.random.binomial(n_new, p_new,  10000)/ n_new\n",
    "old_converted_simul = np.random.binomial(n_old, p_old,  10000)/ n_old\n",
    "p_diffss =new_converted_simul - old_converted_simul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486f4fc",
   "metadata": {},
   "source": [
    "Essentially, we are applying the null proportion to the total size of each page using the binomial distribution. \n",
    " Each element, for example, innp.random.binomial(n_new, p_new, 10000) results in an array with values like [17262, 17250, 17277...]. \n",
    " This array is 10000 elements large When we divide it by n_new, Python broadcasts n_new for each element and we return a proportion for each element.\n",
    " This is essentially is simulating, 10000, the new page conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ac1d4",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the p_diffs. Does this plot look like what you expected? Use the matching problem in the classroom to assure you fully understand what was computed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46046d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce5276b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save p_diffs for later use\n",
    "np.save('p_diffss', p_diffss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7eeb3",
   "metadata": {},
   "source": [
    "The sample size of df2 is large enough that our sampling distribution is bell shaped. As we observed the actual difference in $p_{new} - p_{old}$, based on the confidence interval, we have an equal difference in means between old and new pages. The normal distribution is small, that is, it's between (-0.05 and +0.05)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca0a32",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bc9568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_difference = []\n",
    "for i in range(len(p_diffss)):\n",
    "    if p_diffss[i] > obs_diff:\n",
    "        greater_than_difference.append(p_diffss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c5690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5737"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(greater_than_difference) / len(p_diffss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1ce26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate distribution under the null hypothesis\n",
    "null_vals = np.random.normal(0, np.std(p_diffss), 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b3f1ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAARzUlEQVR4nO3df6xf9X3f8eerdiDdkhYT7jzPtmY38zTBHyWZRZjaP1hZwEAVU6mLiLTGS5FcqSAlWqTJSf6gS4dE2rVU0VIqt1h1trSENoliETbqsExV/+DHJSUEQxk3/BC2DL4NlKSKxuTsvT++H3dfzL2+32t/f9z483xIR99z3udzzvl8uNbrnnvO+R5SVUiS+vBjs+6AJGl6DH1J6oihL0kdMfQlqSOGviR1ZP2sO3Aml1xySW3btm3W3ZCkHymPPfbYX1fV3FLr1nTob9u2jfn5+Vl3Q5J+pCR5cbl1Xt6RpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOrOlv5Eor2bbvazM79gt33DCzY0tnyzN9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6smLoJ3l7kkeSfCvJkST/odW3J3k4yUKSLya5oNUvbMsLbf22oX19otWfSXLtxEYlSVrSKGf6bwA/V1U/DVwO7EpyJfAZ4M6q+ifAa8DNrf3NwGutfmdrR5JLgZuAy4BdwO8mWTfGsUiSVrBi6NfA37bFt7WpgJ8D/rTVDwI3tvndbZm2/uokafV7quqNqnoeWACuGMcgJEmjGemafpJ1SR4HTgCHge8Af1NVJ1uTo8DmNr8ZeAmgrX8deNdwfYltJElTMFLoV9UPq+pyYAuDs/N/NqkOJdmbZD7J/OLi4qQOI0ldWtXTO1X1N8A3gH8BXJTk1AvbtgDH2vwxYCtAW/+TwHeH60tsM3yM/VW1s6p2zs3NraZ7kqQVjPL0zlySi9r8jwPvB55mEP6/2JrtAb7a5g+1Zdr6/1FV1eo3tad7tgM7gEfGNA5J0ghGebXyJuBge9Lmx4B7q+q+JE8B9yT5j8BfAne39ncD/yXJAvAqgyd2qKojSe4FngJOArdU1Q/HOxxJ0pmsGPpV9QTwniXqz7HE0zdV9b+Bf73Mvm4Hbl99NyVJ4+A3ciWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZMfSTbE3yjSRPJTmS5KOt/mtJjiV5vE3XD23ziSQLSZ5Jcu1QfVerLSTZN5khSZKWs36ENieBj1fVN5O8E3gsyeG27s6q+k/DjZNcCtwEXAb8I+DrSf5pW/054P3AUeDRJIeq6qlxDESStLIVQ7+qjgPH2/z3kzwNbD7DJruBe6rqDeD5JAvAFW3dQlU9B5DkntbW0JekKVnVNf0k24D3AA+30q1JnkhyIMmGVtsMvDS02dFWW65++jH2JplPMr+4uLia7kmSVjBy6Cd5B/Al4GNV9T3gLuDdwOUM/hL4rXF0qKr2V9XOqto5Nzc3jl1KkppRrumT5G0MAv8LVfVlgKp6ZWj97wP3tcVjwNahzbe0GmeoS5KmYJSndwLcDTxdVb89VN801OwXgCfb/CHgpiQXJtkO7AAeAR4FdiTZnuQCBjd7D41nGJKkUYxypv8zwC8B307yeKt9EvhQksuBAl4AfgWgqo4kuZfBDdqTwC1V9UOAJLcCDwDrgANVdWRsI5EkrWiUp3f+AsgSq+4/wza3A7cvUb//TNtJkibLb+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjoz0jVxpJdv2fW3WXZA0AkNfOkuz+kX3wh03zOS4Oj94eUeSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOrBj6SbYm+UaSp5IcSfLRVr84yeEkz7bPDa2eJJ9NspDkiSTvHdrXntb+2SR7JjcsSdJSRjnTPwl8vKouBa4EbklyKbAPeLCqdgAPtmWA64AdbdoL3AWDXxLAbcD7gCuA2079opAkTceKoV9Vx6vqm23++8DTwGZgN3CwNTsI3NjmdwOfr4GHgIuSbAKuBQ5X1atV9RpwGNg1zsFIks5sVdf0k2wD3gM8DGysquNt1cvAxja/GXhpaLOjrbZcXZI0JSOHfpJ3AF8CPlZV3xteV1UF1Dg6lGRvkvkk84uLi+PYpSSpGSn0k7yNQeB/oaq+3MqvtMs2tM8TrX4M2Dq0+ZZWW67+JlW1v6p2VtXOubm51YxFkrSCUZ7eCXA38HRV/fbQqkPAqSdw9gBfHap/uD3FcyXwersM9ABwTZIN7QbuNa0mSZqS9SO0+Rngl4BvJ3m81T4J3AHcm+Rm4EXgg23d/cD1wALwA+AjAFX1apJfBx5t7T5dVa+OYxCSpNGsGPpV9RdAlll99RLtC7hlmX0dAA6spoOSpPHxG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOrBj6SQ4kOZHkyaHaryU5luTxNl0/tO4TSRaSPJPk2qH6rlZbSLJv/EORJK1klDP9PwR2LVG/s6oub9P9AEkuBW4CLmvb/G6SdUnWAZ8DrgMuBT7U2kqSpmj9Sg2q6s+TbBtxf7uBe6rqDeD5JAvAFW3dQlU9B5Dkntb2qdV3WZJ0ts7lmv6tSZ5ol382tNpm4KWhNkdbbbn6WyTZm2Q+yfzi4uI5dE+SdLqzDf27gHcDlwPHgd8aV4eqan9V7ayqnXNzc+ParSSJES7vLKWqXjk1n+T3gfva4jFg61DTLa3GGeqSpCk5qzP9JJuGFn8BOPVkzyHgpiQXJtkO7AAeAR4FdiTZnuQCBjd7D519tyVJZ2PFM/0kfwxcBVyS5ChwG3BVksuBAl4AfgWgqo4kuZfBDdqTwC1V9cO2n1uBB4B1wIGqOjLuwUiSzmyUp3c+tET57jO0vx24fYn6/cD9q+qdJGms/EauJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpIyuGfpIDSU4keXKodnGSw0mebZ8bWj1JPptkIckTSd47tM2e1v7ZJHsmMxxJ0pmMcqb/h8Cu02r7gAeragfwYFsGuA7Y0aa9wF0w+CUB3Aa8D7gCuO3ULwpJ0vSsGPpV9efAq6eVdwMH2/xB4Mah+udr4CHgoiSbgGuBw1X1alW9Bhzmrb9IJEkTdrbX9DdW1fE2/zKwsc1vBl4aane01Zarv0WSvUnmk8wvLi6eZfckSUs55xu5VVVAjaEvp/a3v6p2VtXOubm5ce1WksTZh/4r7bIN7fNEqx8Dtg6129Jqy9UlSVN0tqF/CDj1BM4e4KtD9Q+3p3iuBF5vl4EeAK5JsqHdwL2m1SRJU7R+pQZJ/hi4CrgkyVEGT+HcAdyb5GbgReCDrfn9wPXAAvAD4CMAVfVqkl8HHm3tPl1Vp98cliRN2IqhX1UfWmbV1Uu0LeCWZfZzADiwqt5JksZqxdCXtLZs2/e1mR37hTtumNmxNR6+hkGSOuKZ/nlmlmeBktY+z/QlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRcwr9JC8k+XaSx5PMt9rFSQ4nebZ9bmj1JPlskoUkTyR57zgGIEka3TjO9P9lVV1eVTvb8j7gwaraATzYlgGuA3a0aS9w1xiOLUlahUlc3tkNHGzzB4Ebh+qfr4GHgIuSbJrA8SVJyzjX0C/gz5I8lmRvq22squNt/mVgY5vfDLw0tO3RVnuTJHuTzCeZX1xcPMfuSZKGrT/H7X+2qo4l+QfA4SR/NbyyqipJrWaHVbUf2A+wc+fOVW0rSTqzczrTr6pj7fME8BXgCuCVU5dt2ueJ1vwYsHVo8y2tJkmakrMO/SR/P8k7T80D1wBPAoeAPa3ZHuCrbf4Q8OH2FM+VwOtDl4EkSVNwLpd3NgJfSXJqP39UVf89yaPAvUluBl4EPtja3w9cDywAPwA+cg7HliSdhbMO/ap6DvjpJerfBa5eol7ALWd7PEnSufMbuZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR051/9zlpawbd/XZt0FSVqSZ/qS1BHP9CWNbFZ/xb5wxw0zOe75yDN9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkemHvpJdiV5JslCkn3TPr4k9Wyq38hNsg74HPB+4CjwaJJDVfXUJI7nO3Ak6c2m/RqGK4CFqnoOIMk9wG5gIqEv6fwwyxO48+0VENMO/c3AS0PLR4H3DTdIshfY2xb/NskzU+jXJcBfT+E4a5Fj75NjH1E+M8GeTM4/Xm7FmnvhWlXtB/ZP85hJ5qtq5zSPuVY4dsfem57HDtO/kXsM2Dq0vKXVJElTMO3QfxTYkWR7kguAm4BDU+6DJHVrqpd3qupkkluBB4B1wIGqOjLNPixjqpeT1hjH3ifH3qlU1az7IEmaEr+RK0kdMfQlqSPndegnuTjJ4STPts8Ny7Tb09o8m2TPUP2fJ/l2e2XEZ5PktO0+nqSSXDLpsazWpMae5DeT/FWSJ5J8JclFUxrSilZ6xUeSC5N8sa1/OMm2oXWfaPVnklw76j7XgnGPO8nWJN9I8lSSI0k+OsXhrMokfuZt3bokf5nkvikMY7qq6rydgN8A9rX5fcBnlmhzMfBc+9zQ5je0dY8AVwIB/htw3dB2WxnckH4RuGTWY53W2IFrgPVt/jNL7XdG410HfAf4KeAC4FvApae1+VXg99r8TcAX2/ylrf2FwPa2n3Wj7HPW04TGvQl4b2vzTuB/rbVxT2rsQ9v9O+CPgPtmPc5xT+f1mT6DVzwcbPMHgRuXaHMtcLiqXq2q14DDwK4km4CfqKqHavCv4POnbX8n8O+BtXonfCJjr6o/q6qTbfuHGHzXYi34u1d8VNX/AU694mPY8H+TPwWubn/B7Abuqao3qup5YKHtb5R9ztrYx11Vx6vqmwBV9X3gaQbfpl9rJvEzJ8kW4AbgD6Ywhqk730N/Y1Udb/MvAxuXaLPUqyE2t+noEnWS7AaOVdW3xt7j8ZnI2E/zywz+ClgLlhvLkm3aL67XgXedYdtR9jlrkxj332mXQ94DPDzOTo/JpMb+OwxO6P7v2Hu8Bqy51zCsVpKvA/9wiVWfGl6oqkpyzmflSf4e8EkGlzlmatpjP+3YnwJOAl8Y5361diR5B/Al4GNV9b1Z92cakvw8cKKqHkty1Yy7MxE/8qFfVf9quXVJXkmyqaqOt0sWJ5Zodgy4amh5C/A/W33LafVjwLsZXAP8Vru3uQX4ZpIrqurlcxjKqs1g7Kf2/W+Bnweubpd/1oJRXvFxqs3RJOuBnwS+u8K2a/21IRMZd5K3MQj8L1TVlyfT9XM2ibF/APhAkuuBtwM/keS/VtW/mcwQZmDWNxUmOQG/yZtvZv7GEm0uBp5ncCNzQ5u/uK07/Wbm9Uts/wJr80buRMYO7GLwKuy5WY/xtLGsZ3Ajejv//6beZae1uYU339S7t81fxptv6j3H4Cbhivuc9TShcYfBfZzfmfX4pj3207a9ivPwRu7MOzDhfxTvAh4EngW+PhRoO4E/GGr3ywxu5CwAHxmq7wSeZHBn/z/TvsF82jHWauhPZOyt3UvA4236vVmPdajP1zN40uQ7wKda7dPAB9r824E/aWN4BPipoW0/1bZ7hjc/pfWWfa61adzjBn6WwQMKTwz9nN9ywrMWpkn8zIfWn5eh72sYJKkj5/vTO5KkIYa+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sj/A9kSUgb9kKkAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the null distribution\n",
    "plt.hist(null_vals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b295e15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9113"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute p-value\n",
    "# h_alternative : p_new > p_old\n",
    "p_value = (null_vals > obs_diff).mean()\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce5ec5",
   "metadata": {},
   "source": [
    "The actual difference is captured in the population. Since**pvalue >0.05**, we would fail to reject the null hypothesis. 90% of values from our null distribution fall to the right our actual difference. The old page has a higher probability of convertion rate than the new page so I can't reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35335cdf",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results. Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Fill in the below to calculate the number of conversions for each page, as well as the number of individuals who received each page. Let n_old and n_new refer the the number of rows associated with the old page and new pages, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "978eab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# the number of conversions for each page\n",
    "convert_old = df2.query('landing_page == \"old_page\"').converted.sum()  # old page == control group\n",
    "convert_new = df2.query('landing_page == \"new_page\"').converted.sum()  # new page == treatment group\n",
    "# the number of individuals who received each page\n",
    "n_old = df2.query('landing_page == \"old_page\"')['user_id'].nunique()\n",
    "n_new = df2.query('landing_page == \"new_page\"')['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8a6648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17489, 145274)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_old , n_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c73d071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17264, 145310)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_new, n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693b015",
   "metadata": {},
   "source": [
    "m. Now use stats.proportions_ztest to compute your test statistic and p-value. Here is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7f709cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([convert_new, convert_old], [n_new, n_old], alternative = 'larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a35fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69211799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09494168724097551"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    " # Tells us how significant our z-score is\n",
    "norm.cdf(z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c598f5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Tells us what our critical value at 95% confidence is\n",
    "norm.ppf(1-(0.05/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6f37e",
   "metadata": {},
   "source": [
    "n. What do the z-score and p-value you computed in the previous question mean for the conversion rates of the old and new pages? Do they agree with the findings in parts j. and k.?\n",
    "\n",
    "The calculated p-value using proportions_ztest is 0.9. As we know that 90% of values from our null distribution fall to the right or are above our actual mean in parts j and k. In this case, we would fail to reject the null hypothesis as 0.9 > 0.05.\n",
    "\n",
    "In other words, since the z-score of -1.3109241984234394 does not exceed the critical value of 0.9050583127590245, we would fail to reject the null hypothesis thatthe old page has a better or equal converted rate than the new page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21775d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from statsmodels) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from statsmodels) (1.21.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from statsmodels) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from statsmodels) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas>=0.25->statsmodels) (2021.1)\n",
      "Requirement already satisfied: six in c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\mariam atef\\appdata\\local\\programs\\python\\python37-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bac7bf",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "### ToDo 3.1 \n",
    "**a.** Since each row in the `df2` data is either a conversion or no conversion, what type of regression should you be performing in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344d535",
   "metadata": {},
   "source": [
    "Since we only need to yield two different output values that are categorical. We can perform a Logistic Regression model to compare two dummy variables rather than quantitative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea8a05",
   "metadata": {},
   "source": [
    "**b.** The goal is to use **statsmodels** library to fit the regression model you specified in part **a.** above to see if there is a significant difference in conversion based on the page-type a customer receives. However, you first need to create the following two columns in the `df2` dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "214f734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an intercept column :\n",
    "df2['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1dd9990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['ab_page'] = pd.get_dummies(df2.group)['treatment']    # Transform group column to using get_dummies and drop control column\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3273d80",
   "metadata": {},
   "source": [
    "**c.** Use **statsmodels** to instantiate your regression model on the two columns you created in part (b). above, then fit the model to predict whether or not an individual converts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52779396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ab3c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and fitting the regression model (statsmodels) on the two columns\n",
    "ls = sm.Logit(df2.converted, df2[['intercept', 'ab_page']])\n",
    "result = ls.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dcd4cb",
   "metadata": {},
   "source": [
    "**d.** Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c104f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 14 Dec 2021</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:59:26</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Tue, 14 Dec 2021   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        11:59:26   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of model\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9d951",
   "metadata": {},
   "source": [
    "e. What is the p-value associated with ab_page? Why does it differ from the value you found in the Part II?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0180235",
   "metadata": {},
   "source": [
    " What are the null and alternative hypotheses associated with your regression model, and how do they compare to the null and alternative hypotheses in the Part II?\n",
    "\n",
    "In the Part II, we assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5% (i.e. 0.05). We look at an one-tail test to test which page had a higher conversion rate with\n",
    "and\n",
    "\n",
    "hypotheses hnull and halternative the p-value was 0.9. The p-value in Part II is dependent on our alternative hypothesis as we concern with the new page is better than the old page in the entire population.\n",
    "\n",
    "In this case, the result of the p-value of 'ab_page' is 0.19 in our logistic regression model. We only care about our explanatory variable which is ab_page. In regression mode, our null hypothesis now turns into that there is no difference between the two pages and the alternative hypothesis is that their difference is statistically different from one another. That is, logistic regression test is about a two-tail test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4df51",
   "metadata": {},
   "source": [
    "f. Now, you are considering other things that might influence whether or not an individual converts. Discuss why it is a good idea to consider other factors to add into your regression model. Are there any disadvantages to adding additional terms into your regression model?\n",
    "Adding additional features may reveal hidden patterns around the data.However, if these features are irrelevant, this could really hurt our model!\n",
    "Since we already know that the number of old page equals to the number of control group and likewise the size of new pages is the same as the size of treatment group in the data, adding the landing_page column to our logistic regression model might not help in changing the result entirely. So we have one more column which is the timestamp column that could be another factor to influence whether or not an individual converts. The timestamp column allows us to interpret when an user views the page durin a day. The columnd could change the conversion rate by converting the time as three categorical variables such as morning, midday and evening.\n",
    "Our model is now to understand how our x and y variables are related. Furthermore, we want to add more variables into our model. When adding three or more categorical variables that are highly correlated, we need to consider one potential disadavantage that we learn in the lecture, which is Multicollinearity. This might affect our hypothesis testing result to be unhealth and unreliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e491e8",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. You will need to read in the countries.csv dataset and merge together your datasets on the approporiate rows. Here are the docs for joining tables.\n",
    "Adding countries\n",
    "\n",
    "In an effort to refine the model performance and trying to get a better assesment to our statistical test, **Hint:** we will add more factors to the regression model to making a better predeication as we are increasing the training data by merging the countries file and adding the effect based on which country a user lives in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cf87a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcon = pd.read_csv('countries.csv')  # Read the countries file\n",
    "dfcon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04ac4d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        0      US  \n",
       "1          1        0      US  \n",
       "2          1        1      US  \n",
       "3          1        1      US  \n",
       "4          1        0      US  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.merge(dfcon, on='user_id') ## Join with the df2 dataframe\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53df504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['CA', 'UK']] = pd.get_dummies(df2.country)[['CA', 'UK']]\n",
    "# We select CA and UK and drop the US column to make the matrice full rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de3ac42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['new_page'] = pd.get_dummies(df2.landing_page)['new_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "446f5210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 14 Dec 2021</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:59:30</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_page</th>  <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Tue, 14 Dec 2021   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        11:59:30   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "new_page      -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "UK             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a logistic regression model with baselines as US and old_page\n",
    "logit = sm.Logit(df2.converted, df2[['intercept', 'new_page', 'CA', 'UK']])\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b9dc5",
   "metadata": {},
   "source": [
    "The predicted difference in the conversion of a page in CA as compared to the US holding other variables constant : -408.0\n",
    "The predicted difference in the conversion of a page in UK as compared to the US holding other variables constant : -99.0\n",
    "For every one unit increase new page, we predict the conversion of a page to decrease by 0.0149 holding all other variables constant.\n",
    "The predicted converted page if the user views the old page in the US. = -19893\n",
    "Let's calculate VIF value in order to determine whether we have multicollinearity in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ee17fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "y, X = dmatrices('converted ~ new_page + CA + UK', df2, return_type='dataframe')\n",
    "viif = pd.DataFrame()\n",
    "viif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "viif[\"features\"] = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f2d45c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.428940</td>\n",
       "      <td>Intercept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000006</td>\n",
       "      <td>new_page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.017759</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017761</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor   features\n",
       "0    2.428940  Intercept\n",
       "1    1.000006   new_page\n",
       "2    1.017759         CA\n",
       "3    1.017761         UK"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9f4a78",
   "metadata": {},
   "source": [
    "As a result, features' values are not larger than 10 that is, we don't have multicallinearity in our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb8e866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['CA_new'] = df2['new_page'] * df2['CA']\n",
    "df2['UK_new'] = df2['new_page'] * df2['UK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d2a423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 14 Dec 2021</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:59:34</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9865</td> <td>    0.010</td> <td> -206.344</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_page</th>  <td>   -0.0206</td> <td>    0.014</td> <td>   -1.505</td> <td> 0.132</td> <td>   -0.047</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_new</th>    <td>   -0.0469</td> <td>    0.054</td> <td>   -0.872</td> <td> 0.383</td> <td>   -0.152</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_new</th>    <td>    0.0314</td> <td>    0.027</td> <td>    1.181</td> <td> 0.238</td> <td>   -0.021</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0175</td> <td>    0.038</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.091</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>   -0.0057</td> <td>    0.019</td> <td>   -0.306</td> <td> 0.760</td> <td>   -0.043</td> <td>    0.031</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 14 Dec 2021   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        11:59:34   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1920\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9865      0.010   -206.344      0.000      -2.005      -1.968\n",
       "new_page      -0.0206      0.014     -1.505      0.132      -0.047       0.006\n",
       "CA_new        -0.0469      0.054     -0.872      0.383      -0.152       0.059\n",
       "UK_new         0.0314      0.027      1.181      0.238      -0.021       0.084\n",
       "CA            -0.0175      0.038     -0.465      0.642      -0.091       0.056\n",
       "UK            -0.0057      0.019     -0.306      0.760      -0.043       0.031\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a second logistic regression model with baselines as US and old_page\n",
    "logit = sm.Logit(df2.converted, df2[['intercept', 'new_page', 'CA_new', 'UK_new', 'CA', 'UK']])\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d61dd",
   "metadata": {},
   "source": [
    "Based on the results, only the intercept is statically significant. The coefficient of intereaction variables namely CA_new and UK_new are slightly different from the coefficient of new_page itself. I think adding a higher order term between page and country is useful in predicting the conversion of page.\n",
    "For every one unit increase in the conversion for new page from UK, the predicted increase in convertion is by 0.0314.\n",
    "For every one unit increase in the conversion for new page from CA, the predicted decrease in convertion is by -0.0469.\n",
    "The predicted difference between the conversion of pages viewed from CA and from US holding all other variables constant is -0.0175.\n",
    "The predicted difference between the conversion of pages viewed from UK and from US holding all other variables constant is -0.0057."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75bbfd2",
   "metadata": {},
   "source": [
    " Why does it differ from the value you found in Part II?\n",
    "\n",
    "**HINT** In fact, you can interchange the p-values using the following formula. 1-0.19/2 = 0.9 (0.9 should be what you got in part ii). The reason lies in the fact that in part ii, we were concerned with which page had a higher conversion rate, so a one-tailed test. However, in part iii, the nature of a regression test is not concerned with which had a positive or negative change, specifically. It is concerned with if the condition had any effect at all, so a two-tailed test. You can actually see this in the formula to interchange the p-values because is essentially taking the two-tailed p-value, cutting it in half for only one of the tails, and then calculating the right side of the tail since we are concerned with which one is bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8fff73",
   "metadata": {},
   "source": [
    "### Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888b0ad",
   "metadata": {},
   "source": [
    "Based on the available evidence,**we can not reject the null hypothesis**(stating that there is no significant statistical difference related to the new page / country)for many reasons:\n",
    "The p value for the hypothesis testing is greater than the alpha, So the difference between the old page and the new page is not significant and occured by chance.\n",
    "In the regression model also the p value is greater than the alpha and the interaction between the countries and the pages are meaningless or don't have effect on the conversion rate.\n",
    "It seems that the old page is pretty good and enough ,But I can't say If we should continue with the new page or cancel it because The dataset don't have more features.\n",
    "I suggest to run the experiment longer to make the decision of whether to implement the new page or not.\n",
    "\n",
    "There are many factors to consider when designing an A/B test and drawing conclusions based on its results. To conclude, here are some common ones to consider:\n",
    "1-The best metric choice for making the ultimate decision (eg. measuring revenue vs. clicks).\n",
    "2-The practical significance of a conversion rate (the cost of launching a new feature vs. the gain from the increase in conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b02005e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time is 00 minute, 47 seconds\n"
     ]
    }
   ],
   "source": [
    "finish = dt.datetime.now()\n",
    "duration =  finish - start\n",
    "print(f'Total running time is {str(duration)[2:4]} minute, {str(duration)[5:7]} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef8528fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294967295"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
